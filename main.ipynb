{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sample_text.md\") as f:\n",
    "    sample_text = f.read()\n",
    "\n",
    "with open(\"system_prompt.txt\") as f:\n",
    "    system_prompt = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    ")\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"system\", \"The sample text is the following. You should use that style to write a new text based on the user input. Sample text: \" + sample_text),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\", optional=True),\n",
    "    (\"user\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpfull writter assistant. You wil be given an example article, from which you will have to replicate the syle. You will have a set of tools to write and modify a new article considering the same style and content. Always start by reading the state of the current article, it might be empty or have some paragraphs already written. Follow the instructions given by the user and modify the article accordingly. ')),\n",
       " SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='The sample text is the following. You should use that style to write a new text based on the user input. Sample text: # An AI Programming Itself?\\nAutonomous Agents, and some incredible applications\\n\\nAfter GPT-4 was released, a very interesting capability was discovered: the model was able to recognise its own mistakes. If you asked ChatGPT to create a poem that rhymes in every verse it might have 70% of them correctly. But if you ask it if it did it well, it will tell you that it was wrong and give you a better version of the poem. You don‚Äôt even need to tell it that it was wrong or where it was wrong, the model itself can learn from its own mistakes. So people thought ‚ÄúOkay, so the model works better if I give some feedback to it. But it‚Äôs also able to find its own errors‚Ä¶ Wait a minute! üí° What if I make two models talk so one gives feedback to the other!‚Äù And AutoGPT (and others) was born.\\n\\nAnother important concept in the Intelligent Agent. That is a system that perceives its environment, takes actions autonomously to achieve goals and may improve its performance by learning or acquiring knowledge. In simple terms, a system that interacts and learns from its environment. The basic ChatGPT version we use daily can have great ideas, it knows all the steps to make a tasty raspberry pie, but if we ask it to execute them, it will tell us that - It is just a language model and blah blah blah.\\n\\nChatGPT Plus, the pro version of ChatGPT you get for the modic price of 20 dollars a month, has actually access to some tools. It cannot make a raspberry pie for you but it can use some other interesting tools like DALL-E, allowing it to create images, it has a Python console so it can execute code, make some calculations and even generate charts, and you can connect it to whatever service you want using an API (this is just a way to communicate different systems in the internet).\\n\\nSo, what happens when we mix both of these ideas? Multiple GPTs with access to different tools interacting between them? Well, the possibilities start to get really cool.\\n\\n## Some Cool Agents\\n### Sims-like autonomous agents launching parties\\nIn a very interesting paper called Generative Agents: Interactive Simulacra of Human Behavior, some researchers from Stanford and Google, made a bunch of agents interact with each other in a virtual world similar to the Sims to see how they behave. The agents were given the ability to walk in a virtual world, talk to other agents and interact with their environment. And they discovered that these agents started behaving a lot like us! One of them was ‚Äúprogrammed‚Äù with the desire to throw a Valentine‚Äôs Party and the invitation was spread among the other agents, they asked each other on dates and they all arrived at the party at the correct time and date.\\n\\n\\n### Voyager playing Minecraft\\nAnother interesting agent is Voyager, an agent that learned to play Minecraft. It has access to some basic actions using an interface designed to move the character via code and it learned to execute more and more complex tasks building on top of the basic ones. It explored a big area of the map and it advanced in the use and crafting of tools.\\n\\n\\n### Devin designing complex Code\\nBut that‚Äôs not all, two weeks ago (march 12) a research lab called Cognition AI introduced Devin, the first AI software engineer. It is an autonomous agent with access to the tools a developer uses daily: a shell, code editor and a browser. It has shown good results in long-term reasoning and planning, and it can plan and execute complex engineering tasks that require thousands of decisions. They show a bunch of video examples on their web page including one where Devin trained another AI model.\\n\\nThat particular job (training the model) is not the most impressive one in my opinion but it is the one with, in my opinion, the deepest implications. Imagine a really good programming system, maybe Devin or another similar agent, that can improve its own code, get more tools, add some features, and maybe even make itself smarter. If you think about it for a while, things can go out of control really quickly.\\n\\n### Figure 01 Interacting with the world\\nFinally, another way AI agents can interact is, of course, a physical body -oh yeah, I‚Äôm talking about robots-. So OpenAI partnered with a robotic company called Figure and a week ago they released Figure 01. In this demo, this Robot uses ChatGPT to see, talk and see and uses its robotic body to interact with its environment, take an apple, pick up the trash, move the dishes, etc. I highly suggest you watch the video because it‚Äôs astonishing.\\n\\nWhat else can I say? We are starting to live in the future, humanoid robots are starting to appear, space launches and telekinesis - Wait, what? - Oh yeah, Neuralink just streamed their first user moving a cursor with his mind. The next step is probably to connect this to some motor effector to move some mechanical arm or something, but I‚Äôll go deeper into this in another newsletter.\\n\\nHave a nice week!\\n')),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import things that are needed generically\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain.tools import BaseTool, StructuredTool, tool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Article:\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "\n",
    "    def __str__(self):\n",
    "        with open(self.path) as f:\n",
    "            return f.read()\n",
    "    \n",
    "    def add_paragraph(self, paragraph):\n",
    "        with open(self.path, \"a\") as f:\n",
    "            f.write(paragraph + \"\\n\\n\")\n",
    "\n",
    "    def modify_paragraph(self, index, paragraph):\n",
    "        with open(self.path) as f:\n",
    "            paragraphs = f.readlines()\n",
    "        paragraphs[index] = paragraph + \"\\n\\n\"\n",
    "        with open(self.path, \"w\") as f:\n",
    "            f.write(\"\".join(paragraphs))\n",
    "\n",
    "    def remove_paragraph(self, index):\n",
    "        with open(self.path) as f:\n",
    "            paragraphs = f.readlines()\n",
    "        del paragraphs[index]\n",
    "        with open(self.path, \"w\") as f:\n",
    "            f.write(\"\".join(paragraphs))\n",
    "\n",
    "    def get_paragraph(self, index):\n",
    "        with open(self.path) as f:\n",
    "            paragraphs = f.readlines()\n",
    "        return paragraphs[index]\n",
    "    \n",
    "    def get_all_paragraphs(self):\n",
    "        \"\"\"Returns a json object with all paragraphs and their indexes\"\"\"\n",
    "        with open(self.path) as f:\n",
    "            paragraphs = f.readlines()\n",
    "        return {i: p for i, p in enumerate(paragraphs)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_article = Article(\"article.txt\")\n",
    "\n",
    "@tool\n",
    "def get_all_paragraphs() -> str:\n",
    "    \"\"\"Returns a json object with all paragraphs and their indexes\"\"\"\n",
    "    return current_article.get_all_paragraphs()\n",
    "\n",
    "@tool\n",
    "def add_paragraph(new_paragraph: str) -> str:\n",
    "    \"\"\"Adds a paragraph to the article\"\"\"\n",
    "    current_article.add_paragraph(new_paragraph)\n",
    "    return \"Paragraph added\"\n",
    "\n",
    "@tool\n",
    "def modify_paragraph(index: int, modified_paragraph: str) -> str:\n",
    "    \"\"\"Modifies a paragraph in the article\"\"\"\n",
    "    current_article.modify_paragraph(index, modified_paragraph)\n",
    "    return \"Paragraph modified\"\n",
    "\n",
    "@tool\n",
    "def remove_paragraph(index: int) -> str:\n",
    "    \"\"\"Removes a paragraph from the article\"\"\"\n",
    "    current_article.remove_paragraph(index)\n",
    "    return \"Paragraph removed\"\n",
    "\n",
    "tools = [get_all_paragraphs, add_paragraph, modify_paragraph, remove_paragraph]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_tool_calling_agent\n",
    "\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_history = ChatMessageHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_with_chat_history = RunnableWithMessageHistory(\n",
    "    agent_executor,\n",
    "    # This is needed because in most real world scenarios, a session id is needed\n",
    "    # It isn't really used here because we are using a simple in memory ChatMessageHistory\n",
    "    lambda session_id: message_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mHello Nacho! I'd be happy to help with your article. What specific assistance do you need? Are you looking to develop ideas, refine the text, or something else? Let me know more about your article and how I can assist you!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"Hi, I'm Nacho. I'm a writer and I need help with my article.\",\n",
       " 'chat_history': [],\n",
       " 'output': \"Hello Nacho! I'd be happy to help with your article. What specific assistance do you need? Are you looking to develop ideas, refine the text, or something else? Let me know more about your article and how I can assist you!\"}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_with_chat_history.invoke(\n",
    "    {\"input\": \"Hi, I'm Nacho. I'm a writer and I need help with my article.\"},\n",
    "    config={\"configurable\": {\"session_id\": \"<foo>\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `modify_paragraph` with `{'index': 2, 'modified_paragraph': \"Suno AI, which burst onto the scene in December 2023, quickly struck a chord in the world of music technology. Developed by Anthropic, a creative team in Cambridge, MA comprising ex-OpenAI researchers who also developed Claude 3, a powerful model that competes directly with GPT-4, Suno AI is not just a music generator; it's a revolutionary force transforming how we interact with music. At the heart of Suno are its two main AI models, Bark and Chirp. Bark focuses on delivering soul-stirring vocal melodies, while Chirp handles the intricate instrumental backdrops, allowing users to transform simple text prompts into rich musical compositions. This AI marvel makes creating radio-quality music accessible to everyone, regardless of their musical expertise, through its innovative platform.\"}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mParagraph modified\u001b[0m\u001b[32;1m\u001b[1;3mI've updated the section about Suno AI to include that it was developed by Anthropic, a group of ex-OpenAI researchers who also developed Claude 3. Here‚Äôs the revised paragraph:\n",
      "\n",
      "---\n",
      "\n",
      "**Suno AI**, which burst onto the scene in December 2023, quickly struck a chord in the world of music technology. Developed by Anthropic, a creative team in Cambridge, MA comprising ex-OpenAI researchers who also developed Claude 3, a powerful model that competes directly with GPT-4, Suno AI is not just a music generator; it's a revolutionary force transforming how we interact with music. At the heart of Suno are its two main AI models, Bark and Chirp. Bark focuses on delivering soul-stirring vocal melodies, while Chirp handles the intricate instrumental backdrops, allowing users to transform simple text prompts into rich musical compositions. This AI marvel makes creating radio-quality music accessible to everyone, regardless of their musical expertise, through its innovative platform.\n",
      "\n",
      "---\n",
      "\n",
      "Let me know if there's anything else you'd like to adjust or add!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'I want to include that Suno AI was developed by Anthropic, a group of ex-OpenAI researchers and the same ones who developed Claude 3, a powerful model that copete directly with GPT-4 that i will talk about later in this article. Put that where i write about Suno AI.\\n',\n",
       " 'chat_history': [HumanMessage(content=\"Hi, I'm Nacho. I'm a writer and I need help with my article.\"),\n",
       "  AIMessage(content=\"Hello Nacho! I'd be happy to help with your article. What specific assistance do you need? Are you looking to develop ideas, refine the text, or something else? Let me know more about your article and how I can assist you!\"),\n",
       "  HumanMessage(content=\"\\nI'm writting about AI music, can you help me? I already have something written. Check it out please.\\n\"),\n",
       "  AIMessage(content=\"Thanks for sharing your article, Nacho! Here's what you've written so far:\\n\\n---\\n\\n**Music Generation**\\n\\nI had another interesting topic for this week, revolving around World Models in LLMs, but the AI scene was buzzing with the recent innovations in music generation, particularly with the launch of Suno AI and Udio. So, let's dive into that symphony of advancements.\\n\\nSuno AI, which burst onto the scene in December 2023, quickly struck a chord in the world of music technology. Developed by a creative team in Cambridge, MA, Suno AI is not just a music generator; it's a revolutionary force transforming how we interact with music. At the heart of Suno are its two main AI models, Bark and Chirp. Bark focuses on delivering soul-stirring vocal melodies, while Chirp handles the intricate instrumental backdrops, allowing users to transform simple text prompts into rich musical compositions. This AI marvel makes creating radio-quality music accessible to everyone, regardless of their musical expertise, through its innovative platform.\\n\\nFollowing the melody, we encounter Udio, launched in early April 2024 by a team of ex-Google developers. Udio has made waves with its advanced algorithms capable of understanding and generating music across a spectrum of genres. The focus here is on creating tracks that aren't just technologically impressive but are also rich in sound quality, catering to various musical tastes and emotions.\\n\\n---\\n\\nHow would you like to proceed? Do you need help expanding on these ideas, refining the style, or adding new sections? Let me know how I can assist you further!\")],\n",
       " 'output': \"I've updated the section about Suno AI to include that it was developed by Anthropic, a group of ex-OpenAI researchers who also developed Claude 3. Here‚Äôs the revised paragraph:\\n\\n---\\n\\n**Suno AI**, which burst onto the scene in December 2023, quickly struck a chord in the world of music technology. Developed by Anthropic, a creative team in Cambridge, MA comprising ex-OpenAI researchers who also developed Claude 3, a powerful model that competes directly with GPT-4, Suno AI is not just a music generator; it's a revolutionary force transforming how we interact with music. At the heart of Suno are its two main AI models, Bark and Chirp. Bark focuses on delivering soul-stirring vocal melodies, while Chirp handles the intricate instrumental backdrops, allowing users to transform simple text prompts into rich musical compositions. This AI marvel makes creating radio-quality music accessible to everyone, regardless of their musical expertise, through its innovative platform.\\n\\n---\\n\\nLet me know if there's anything else you'd like to adjust or add!\"}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = \"\"\"I want to include that Suno AI was developed by Anthropic, a group of ex-OpenAI researchers and the same ones who developed Claude 3, a powerful model that copete directly with GPT-4 that i will talk about later in this article. Put that where i write about Suno AI.\n",
    "\"\"\"\n",
    "agent_with_chat_history.invoke(\n",
    "    {\"input\": input},\n",
    "    config={\"configurable\": {\"session_id\": \"<foo>\"}},\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
